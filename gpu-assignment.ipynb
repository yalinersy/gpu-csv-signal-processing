{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31259,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T11:29:57.207329Z","iopub.execute_input":"2026-02-15T11:29:57.207695Z","iopub.status.idle":"2026-02-15T11:29:57.443916Z","shell.execute_reply.started":"2026-02-15T11:29:57.207638Z","shell.execute_reply":"2026-02-15T11:29:57.443006Z"}},"outputs":[{"name":"stdout","text":"Sun Feb 15 11:29:57 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n+-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install numba","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T11:31:25.047839Z","iopub.execute_input":"2026-02-15T11:31:25.048492Z","iopub.status.idle":"2026-02-15T11:31:28.944049Z","shell.execute_reply.started":"2026-02-15T11:31:25.048451Z","shell.execute_reply":"2026-02-15T11:31:28.943316Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (0.60.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba) (0.43.0)\nRequirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.12/dist-packages (from numba) (2.0.2)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nfrom numba import cuda\nimport math\nimport time\nimport os\n\n# Create folders\nos.makedirs(\"input_csv\", exist_ok=True)\nos.makedirs(\"output_csv\", exist_ok=True)\n\n# Generate 60 CSV files with random numbers\nfor i in range(60):\n    data = np.random.randint(1, 100, 2000)\n    np.savetxt(f\"input_csv/file_{i}.csv\", data, fmt=\"%d\")\n\n# CUDA Kernel\n@cuda.jit\ndef square_kernel(input_arr, output_arr):\n    idx = cuda.grid(1)\n    if idx < input_arr.size:\n        output_arr[idx] = input_arr[idx] * input_arr[idx]\n\nstart = time.time()\n\n# Process all CSV files\nfor file in os.listdir(\"input_csv\"):\n    data = np.loadtxt(f\"input_csv/{file}\")\n\n    d_input = cuda.to_device(data)\n    d_output = cuda.device_array_like(data)\n\n    threads_per_block = 256\n    blocks = math.ceil(data.size / threads_per_block)\n\n    square_kernel[blocks, threads_per_block](d_input, d_output)\n\n    result = d_output.copy_to_host()\n    np.savetxt(f\"output_csv/{file}\", result, fmt=\"%d\")\n\nend = time.time()\n\nprint(\"Processed 60 CSV files\")\nprint(\"Time Taken:\", end - start, \"seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T11:31:41.038950Z","iopub.execute_input":"2026-02-15T11:31:41.039273Z","iopub.status.idle":"2026-02-15T11:31:44.556135Z","shell.execute_reply.started":"2026-02-15T11:31:41.039244Z","shell.execute_reply":"2026-02-15T11:31:44.555478Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/numba_cuda/numba/cuda/dispatcher.py:680: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n  warn(NumbaPerformanceWarning(msg))\n","output_type":"stream"},{"name":"stdout","text":"Processed 60 CSV files\nTime Taken: 1.5143680572509766 seconds\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T11:37:54.613647Z","iopub.execute_input":"2026-02-15T11:37:54.614311Z","iopub.status.idle":"2026-02-15T11:37:54.783389Z","shell.execute_reply.started":"2026-02-15T11:37:54.614278Z","shell.execute_reply":"2026-02-15T11:37:54.782516Z"}},"outputs":[{"name":"stdout","text":"Sun Feb 15 11:37:54 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n+-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   41C    P0             33W /  250W |     263MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":4}]}